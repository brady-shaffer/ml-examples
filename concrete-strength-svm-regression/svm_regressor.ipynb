{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Explore Concrete Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df = pd.read_csv(\"concrete_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"csMPa\" is the compresive strength, the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    sns.set_theme(style=\"white\")\n",
    "    corr = df.corr()\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    # cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    sns.heatmap(corr, mask=mask, cmap=\"coolwarm\", center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(concrete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity doesn't appear to be a problem with this dataset, so we'll retain all the existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(df):\n",
    "    sns.set(font_scale=0.6)\n",
    "    g = sns.pairplot(\n",
    "        concrete_df, \n",
    "        diag_kind=\"kde\", \n",
    "        height=0.9, \n",
    "        aspect=1.4, \n",
    "        plot_kws={'alpha': 0.2, 's': 5}\n",
    "    )\n",
    "    for i, j in zip(*plt.np.triu_indices_from(g.axes, 1)):\n",
    "        g.axes[i, j].set_visible(False)\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        ax.xaxis.label.set_rotation(0)\n",
    "        ax.yaxis.label.set_rotation(90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairplot(concrete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"age\" feature will need a log transform, which we'll do below.  Several other features exhibit a bimodal distribution, but with significant differences between major and minor modes.  We'll keep them as is for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(concrete_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"csMPa\"\n",
    "feature_cols = [col for col in concrete_df.columns if col != label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_set[feature_cols], train_set[[label_col]]\n",
    "X_test, y_test = test_set[feature_cols], test_set[[label_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.feature_names_ = X.columns\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        assert self.n_features_in_ == X.shape[1]\n",
    "\n",
    "        return np.log(X)\n",
    "\n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return self.feature_names_\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return np.exp(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a custom class for the log transform to allow for the predict method to be used (this requires the inverse_transform method to be implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "log_transformer = LogTransformer()\n",
    "\n",
    "log_features = [\"age\"]\n",
    "normal_features = [col for col in X_train.columns if col not in log_features]\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    (\"standardize\", std_scaler, normal_features),\n",
    "    (\"log_transform\", log_transformer, log_features),\n",
    "])\n",
    "\n",
    "svm_reg_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing_pipeline),\n",
    "    (\"svm_reg\", SVR()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Randomized Search for Optimal Parameters Using SVM Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter ranges are based on common parameter values for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lower_bound = 0.01\n",
    "c_upper_bound = 15.0\n",
    "gamma_lower_bound = 0.001\n",
    "gamma_upper_bound = 15.0\n",
    "\n",
    "param_distributions = {\n",
    "    \"svm_reg__kernel\": [\"rbf\", \"linear\"],\n",
    "    \"svm_reg__gamma\": [\"auto\", \"scale\"],\n",
    "    \"svm_reg__C\": uniform(loc=c_lower_bound, scale=c_upper_bound - c_lower_bound),\n",
    "}\n",
    "\n",
    "svr_rnd_search = RandomizedSearchCV(\n",
    "    svm_reg_pipeline, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=50, \n",
    "    scoring=\"neg_root_mean_squared_error\", \n",
    "    cv=5, \n",
    "    verbose=0, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rnd_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(svr_rnd_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = svr_rnd_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Best Estimator on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test[\"csMPa\"], y_pred, squared=False)\n",
    "print(f\"RMSE for best model = {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = 0.95\n",
    "squared_errors = (y_pred - y_test[\"csMPa\"]) ** 2\n",
    "confidence_interval = np.sqrt(\n",
    "    stats.t.interval(\n",
    "        confidence, \n",
    "        len(squared_errors) - 1, \n",
    "        loc=squared_errors.mean(), \n",
    "        scale=stats.sem(squared_errors)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE Confidence interval = {confidence_interval[0]:.2} to {confidence_interval[1]:.2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the RMSE is slightly higher, the model doesn't appear to be significantly overfitting on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
